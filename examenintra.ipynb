{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# leba3207\n",
        "\n",
        "from tqdm import tqdm\n",
        "import heapq\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import difflib\n",
        "from functools import partial\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import KMeans"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chargement des donn\u00e9es des diff\u00e9rents fichiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_folder = 'data/'\n",
        "\n",
        "journal_file = 'api_journal11-13-17.csv'\n",
        "price_file = 'api_price11-13-17.csv'\n",
        "influence_file = 'estimated-article-influence-scores-2015.csv'\n",
        "\n",
        "journal = pd.read_csv(data_folder + journal_file, sep=',', encoding='latin1')\n",
        "price = pd.read_csv(data_folder + price_file, sep=',', index_col=0)\n",
        "influence = pd.read_csv(data_folder + influence_file, sep=',', index_col=0)\n",
        "\n",
        "journal.name = 'journal'\n",
        "price.name = 'price'\n",
        "influence.name = 'influence'\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_uniqueness_attributes(table):\n",
        "    return table.nunique(axis=0)\n",
        "\n",
        "\n",
        "def get_ratio_missing_values(table):\n",
        "    return table.isnull().sum() * 100 / len(table)\n",
        "\n",
        "\n",
        "def get_unique_values_of_attribute(table, header):\n",
        "    return table[header].unique()\n",
        "\n",
        "\n",
        "def lowercase_columns(table, headers):\n",
        "    for header in headers:\n",
        "        table[header] = table[header].str.lower()\n",
        "\n",
        "\n",
        "def get_df_duplicated_rows_dropped(table):\n",
        "    return table.drop_duplicates()\n",
        "\n",
        "\n",
        "def plot_categories_frequency(table, header):\n",
        "    fig, ax = plt.subplots()\n",
        "    table[header].value_counts()[0:5].plot(ax=ax, kind='bar')\n",
        "    plt.title(f'Pr\u00e9sentation des 5 valeurs les plus fr\u00e9quentes\\nde l\\'attribut {header} pour la table {table.name}')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_mean_price_per_year():\n",
        "    mean_price_per_year = {}\n",
        "    for index, p in price.iterrows():\n",
        "        year = p['date_stamp'].year\n",
        "        if year in mean_price_per_year:\n",
        "            mean_price_per_year[year] += p['price']\n",
        "        else:\n",
        "            mean_price_per_year[year] = p['price']\n",
        "\n",
        "    for year, value in mean_price_per_year.items():\n",
        "        mean_price_per_year[year] /= len(price[price['price'] != 0])\n",
        "    return {k: v for k, v in sorted(mean_price_per_year.items(), key=lambda item: item[0], reverse=True)}\n",
        "\n",
        "\n",
        "def rename_df_headers(table, dict_headers):\n",
        "    return table.rename(columns=dict_headers)\n",
        "\n",
        "\n",
        "def get_score_sequence_matching(s, c1, category):\n",
        "    if s[c1] is np.nan:\n",
        "        return 0\n",
        "    return difflib.SequenceMatcher(None, s[c1], category).ratio()\n",
        "\n",
        "\n",
        "def get_empty_attribute_to_remove(table):\n",
        "    headers = []\n",
        "    for header in table.columns:\n",
        "        if table[header].isna().sum() * 100 / len(table) > 50:\n",
        "            headers.append(header)\n",
        "    return headers\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 1: Exploration-Description\n",
        "## Pr\u00e9senter une description de chacun des attributs des 3 tables, avec des graphiques pour la visualisation des statistiques descriptives au besoin.\n",
        "\n",
        "### Table journal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(journal.head())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "issn: identifiant de la revue\n",
        "Les valeurs de cet attribut semblent suivre un format particulier tel que: 4 digits - 4 digits\n",
        "Etant donn\u00e9 que l'identifiant sp\u00e9cifie chaque revue, cet attribut devrait pr\u00e9senter des valeurs uniques pour chacun\n",
        "des objets.\n",
        "\n",
        "journal_name: nom textuel de la revue\n",
        "Les valeurs sont textuelles, ne suivant pas de valeurs cat\u00e9gorielles particuli\u00e8re \u00e0 priori. Il n'existe pas de format\n",
        "sp\u00e9cifi\u00e9, les valeurs s'en retrouvent donc tr\u00e8s inconsistantes.\n",
        "\n",
        "pub_name: nom de l'\u00e9diteur de la revue\n",
        "Les valeurs sont textuelles, ne suivant pas de valeurs cat\u00e9gorielles particuli\u00e8re \u00e0 priori. Il n'existe pas de format\n",
        "sp\u00e9cifi\u00e9, les valeurs s'en retrouvent donc tr\u00e8s inconsistantes.\n",
        "\n",
        "is_hybrid: indique si la revue est hybride. Si oui, cela signifie que cette revue est disponible par abonnement o\u00f9 \n",
        "certains articles sont en libre acc\u00e8s et d'autres payants, comme l'indique le site http://flourishoa.org/about.\n",
        "\n",
        "category: renseigne sur la/les cat\u00e9gorie(s) des sujets abord\u00e9s par la revue\n",
        "Les valeurs sont textuelles et sont cat\u00e9gorielles. Chaque objet peut poss\u00e9der des valeurs multiples pour cet attribut. \n",
        "La s\u00e9paration entre les diff\u00e9rentes valeurs semblent \u00eatre inconsistante.\n",
        "\n",
        "url: indique l'adresse web url du site de la revue\n",
        "\n",
        "\n",
        "Les attributs journal_name, pub_name et category \u00e9tant des donn\u00e9es textuelles tr\u00e8s inconsistantes, je d\u00e9cide avant tout\n",
        "traitement et \u00e9tude suppl\u00e9mentaire de transformer les valeurs en minuscule pour limiter au maximum l'inconsistence\n",
        "inutile entre les diff\u00e9rentes valeurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lowercase_columns(journal, ['journal_name', 'pub_name', 'category'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Valeurs uniques des attributs de journal pr\u00e9sentant {journal.shape[0]} objets:\\n\"\n",
        "      f\"{get_uniqueness_attributes(journal)}\")\n",
        "print(f\"Ratio de valeurs vides pour les attributs de journal:\\n\"\n",
        "      f\"{get_ratio_missing_values(journal)}\")\n",
        "\n",
        "print(f\"Valeurs possibles pour l'attribut is_hybrid de journal:\\n\"\n",
        "      f\"{get_unique_values_of_attribute(journal, 'is_hybrid')}\")\n",
        "print(f\"Valeurs possibles pour l'attribut category de journal:\\n\"\n",
        "      f\"{get_unique_values_of_attribute(journal, 'category')}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les attributs category et url pr\u00e9sentent un nombre cons\u00e9quent de valeurs manquantes.\n",
        "L'attribut issn pr\u00e9sente, comme souhait\u00e9,  des valeurs uniques pour chacun de ses objets.\n",
        "\n",
        "On remarque qu'il existe uniquement deux valeurs pour l'attribut is_hybrid (soit 1 soit 0), ce qui semble logique. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Valeurs possibles de pub_name quand is_hybrid vaut 1:\\n\"\n",
        "      f\"{journal[journal['is_hybrid'] == 1]['pub_name'].unique()}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela nous montre que parmi le grand nombre d'\u00e9diteurs possibles, seuls 4 permettent des revues hybrides."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_categories_frequency(journal, 'pub_name')\n",
        "plot_categories_frequency(journal, 'category')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Malgr\u00e9 l'inconsistence des valeurs de ces deux attributs, on s'aper\u00e7oit n\u00e9anmoins que certaines cat\u00e9gories et \u00e9diteurs\n",
        "sont plus fr\u00e9quents que d'autres.\n",
        "\n",
        "Cette table m\u00e9riterait un travail sur l'inconsistence des valeurs de category afin de pouvoir approfondir l'\u00e9tude de cet\n",
        "attribut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(price.head())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "price: information du co\u00fbt d'une publication pour la revue, en dollar US, \u00e0 une date pr\u00e9cis\u00e9e dans l'attribut date_stamp\n",
        "Si celui-ci est \u00e0 0, on peut compendre qu'une publication au sein de cette revue est gratuite.\n",
        "\n",
        "date_stamp: horodatage de l'information de co\u00fbt d'une publication au sein d'une revue donn\u00e9e.\n",
        "Cet attribut suit un format ann\u00e9es-mois-jour\n",
        "\n",
        "journal_id: identifiant de la revue (permet la liaison avec la table journal, qui pr\u00e9sente le m\u00eame attribut sous le nom\n",
        "issn)\n",
        "Les valeurs semblent suivre consistantement un format du type: 4 digits - 4 digits. \n",
        "\n",
        "influence_id: identifiant de l'influence (permet la liaison avec la table influence afin d'avoir des informations sur \n",
        "l'influence d'une revue)\n",
        "Les valeurs suivent un format 4 digits.\n",
        "\n",
        "url: indique l'adresse web url du site de l'auteur\n",
        "\n",
        "license: indique le type de license utilis\u00e9 par la revue pour les diff\u00e9rents articles qui y sont publi\u00e9s.\n",
        "\n",
        "\n",
        "Comme pr\u00e9cis\u00e9 dans les descriptions des donn\u00e9es sur le site, une revue peut disposer de prix diff\u00e9rents en fonction des\n",
        "leurs horodatages. Il serait donc normal qu'une revue dispose de plusieurs de plusieurs prix selon diff\u00e9rents \n",
        "horodatages. Cependant, chaque horodatage pour une revue devrait \u00eatre unique sinon cela pourrait \u00eatre consid\u00e9r\u00e9 comme \n",
        "un doublon.\n",
        "\n",
        "On convertit tout d'abord l'attribut date_stamp en type date."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "price['date_stamp'] = pd.to_datetime(price['date_stamp'], errors='coerce', format='%Y-%m-%d')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Valeurs uniques des attributs de price pr\u00e9sentant {price.shape[0]} objets:\\n\"\n",
        "      f\"{get_uniqueness_attributes(price)}\")\n",
        "print(f\"Ratio de valeurs vides pour les attributs de price:\\n\"\n",
        "      f\"{get_ratio_missing_values(price)}\")\n",
        "\n",
        "print(f\"Exemples de valeurs possibles pour l'attribut influence_id de price:\\n\"\n",
        "      f\"{get_unique_values_of_attribute(price, 'influence_id')[1:8]}\")\n",
        "print(f\"Valeurs possibles pour l'attribut license de price:\\n\"\n",
        "      f\"{get_unique_values_of_attribute(price, 'license')}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les attributs influence_id, url et license pr\u00e9sentent une majorit\u00e9 de valeurs manquantes, ces attributs semblent donc\n",
        "peu porteurs d'information.\n",
        "\n",
        "On s'int\u00e9resse principalement aux valeurs de l'attribut price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mean_price_per_year = get_mean_price_per_year()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.bar(range(len(mean_price_per_year)), mean_price_per_year.values())\n",
        "plt.xticks(range(len(mean_price_per_year)), mean_price_per_year.keys())\n",
        "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
        "plt.title(\"Moyenne par ann\u00e9e des co\u00fbts de publications dans les revues\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si les deux derni\u00e8res ann\u00e9es (2016, 2017) sont les ann\u00e9es o\u00f9 les co\u00fbts de publications se sont r\u00e9v\u00e9l\u00e9s les plus \n",
        "importants, la moyenne du co\u00fbt de publication de'ann\u00e9e 2016 semble \u00eatre quand m\u00eame 4 fois plus \u00e9l\u00e9v\u00e9 qu'en 2017.\n",
        "Les co\u00fbts de publication ne semblent pas \u00eatre stables en fonction des ann\u00e9es."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table influence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(influence.head())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "journal_name: nom textuel de la revue (semble \u00eatre un duplicata de l'attribut journal_name de la table journal).\n",
        "Les valeurs sont textuelles, ne suivant pas de valeurs cat\u00e9gorielles particuli\u00e8re \u00e0 priori.\n",
        "\n",
        "issn: identifiant du journal (semble \u00eatre un duplicata de l'attribut issn de la table journal)\n",
        "Les valeurs de cet attribut semblent suivre un format particulier tel que: 4 digits - 4 digits\n",
        "\n",
        "citation_count_sum: indique le nombre de citations total de la revue \n",
        "\n",
        "paper_count_sum: indique le nombre de papiers dans lequel la revue est cit\u00e9e\n",
        "\n",
        "avg_cites_per_paper: indique la moyenne des citations par papier de la revue\n",
        "Cet attribut semble \u00eatre un rapport des attributs citation_count_sum et paper_count_sum, permettant de donner un \n",
        "r\u00e9sultat plus g\u00e9n\u00e9ral sur les citations d'une revue.\n",
        "\n",
        "proj_ai: information sur le score d'influence des articles de la revue. Celui-ci semble \u00eatre plus \u00e9lev\u00e9 plus la \n",
        "moyenne des citations par papier de la revue (correspond \u00e0 la l'attribut avg_cites_per_paper) est grand.\n",
        "\n",
        "proj_ai_year: sp\u00e9cification de l'ann\u00e9e o\u00f9 l'information sur le score d'influence des articles du journal a \u00e9t\u00e9 \u00e9tablie\n",
        "\n",
        "\n",
        "L'attribut issn devrait identifi\u00e9 chaque objet de la table, celui-ci devrait donc \u00eatre unique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "influence['proj_ai_year'] = pd.to_datetime(influence['proj_ai_year'], errors='coerce', format='%Y')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Valeurs uniques des attributs de influence pr\u00e9sentant {influence.shape[0]} objets:\\n\"\n",
        "      f\"{get_uniqueness_attributes(influence)}\")\n",
        "print(f\"Ratio de valeurs vides pour les attributs de influence:\\n\"\n",
        "      f\"{get_ratio_missing_values(influence)}\")\n",
        "\n",
        "print(f\"Valeurs possibles pour l'attribut proj_ai_year de influence:\\n\"\n",
        "      f\"{get_unique_values_of_attribute(influence, 'proj_ai_year')}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'attribut proj_ai_year ne pr\u00e9sentant qu'une seule valeur nous indique que les valeurs de l'attribut proj_ai ont toutes\n",
        "\u00e9t\u00e9 \u00e9tablies \u00e0 la m\u00eame p\u00e9riode, 2015. L'attribut proj_ai_year nous importe donc peu d'information pour chaque objet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 2: Pr\u00e9traitement-Repr\u00e9sentation\n",
        "## A. Effectuer un pr\u00e9traitement des donn\u00e9es pour supprimer les duplications et corriger les incoh\u00e9rences s\u2019il y en a."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table journal\n",
        "Dans un premier temps, on \u00e9limine les objets pr\u00e9sentant des objets dupliqu\u00e9s sur tous les attributs.\n",
        "On se base sur l'attribut issn qui devrait \u00eatre unique pour chaque objet de la table, on v\u00e9rifie son unicit\u00e9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nb = len(journal)\n",
        "journal = get_df_duplicated_rows_dropped(journal)\n",
        "print(f\"Nombre d'objets dupliqu\u00e9s \u00e9limin\u00e9s dans journal: {nb - len(journal)}\")\n",
        "\n",
        "check = np.logical_not(journal['issn'].duplicated().any())\n",
        "print(f\"Unicit\u00e9 de l'attribut issn dans la table journal: {check}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table price\n",
        "Lors de l'importation des donn\u00e9es, les indexes de la table \u00e9taient fournis. L'unicit\u00e9 des indexes de la table sont \u00e0 \n",
        "v\u00e9rifier.\n",
        "\n",
        "On \u00e9limine les objets pr\u00e9sentant des objets dupliqu\u00e9s sur tous les attributs, au cas o\u00f9 il en existe.\n",
        "\n",
        "Dans un second temps, comme expliqu\u00e9 dans la question pr\u00e9c\u00e9dente, les objets de la table price se doivent d'\u00eatre\n",
        "uniques selon deux attributs, date_stamp et journal_id. Chaque revue peut pr\u00e9senter plusieurs co\u00fbts de publication \u00e0 des\n",
        "horodatages diff\u00e9rents. S'il existe 2 horodatages identiques pour la m\u00eame revue, alors ce serait des objets consid\u00e9r\u00e9s\n",
        "comme dupliqu\u00e9s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "check = np.logical_not(price.index.duplicated().any())\n",
        "print(f\"Unicit\u00e9 des indexes de la table price: {check}\")\n",
        "\n",
        "nb = len(price)\n",
        "price = get_df_duplicated_rows_dropped(price)\n",
        "print(f\"Nombre d'objets enti\u00e8rement identifiques \u00e0 \u00e9liminer dans la table price: {nb - len(price)}\")\n",
        "\n",
        "duplicated_rows = price[price[['date_stamp', 'journal_id']].duplicated(keep=False)]\n",
        "print(f'Nombre de duplicata selon les attributs date_stamp et journal_id: {len(duplicated_rows)}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il existe des duplicata ambigus que l'on d\u00e9cide de traiter un \u00e0 un.\n",
        "\n",
        "Premier cas: un des objets pr\u00e9sente un prix nul, on d\u00e9cide de choisir de l'\u00e9liminer arbitrairement au profit de l'autre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(duplicated_rows.iloc[0].fillna(0) == duplicated_rows.iloc[1].fillna(0))\n",
        "price = price.drop(duplicated_rows.index.values[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deuxi\u00e8me cas: leur valeur du prix est diff\u00e9rente d'un l\u00e9ger \u00e9cart, on d\u00e9cide de garder la deuxi\u00e8me de mani\u00e8re\n",
        "arbitraire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(duplicated_rows.iloc[40].fillna(0) == duplicated_rows.iloc[41].fillna(0))\n",
        "price = price.drop(duplicated_rows.index.values[40])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Troisi\u00e8me cas: seule la valeur de license est diff\u00e9rente, on d\u00e9cide de garder la premi\u00e8re de mani\u00e8re arbitraire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for i in range(3, 39, 2):\n",
        "    price = price.drop(duplicated_rows.index.values[i])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table influence\n",
        "Lors de l'importation des donn\u00e9es, les indexes de la table \u00e9taient fournis. L'unicit\u00e9 des indexes de la table sont \u00e0 \n",
        "v\u00e9rifier.\n",
        "\n",
        "On se base sur l'attribut issn qui devrait \u00eatre unique pour chaque objet de la table, on v\u00e9rifie son unicit\u00e9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "check = np.logical_not(influence.index.duplicated().any())\n",
        "print(f\"Unicit\u00e9 des indexes de la table influence: {check}\")\n",
        "\n",
        "nb = len(influence)\n",
        "influence = get_df_duplicated_rows_dropped(influence)\n",
        "print(f\"Nombre d'objets enti\u00e8rement identifiques \u00e0 \u00e9liminer dans la table influence: {nb - len(influence)}\")\n",
        "\n",
        "check = np.logical_not(influence['issn'].duplicated().any())\n",
        "print(f\"Unicit\u00e9 de l'attribut issn dans la table influence: {check}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme expliqu\u00e9 dans la question pr\u00e9c\u00e9dente, l'attribut avg_cites_per_paper est un r\u00e9sultat du rapport entre \n",
        "citation_count_sum et paper_count_sum. Les valeurs de l'attribut avg_cites_per_paper sont donc \u00e0 v\u00e9rifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "check = influence.apply(\n",
        "    lambda x: True if x['citation_count_sum'] / x['paper_count_sum'] == x['avg_cites_per_paper'] else False, axis=1)\n",
        "print(\n",
        "    f'Rapport citation_count_sum et paper_count_sum est bien \u00e9gal \u00e0 avg_cites_per_paper pour tous objets: {check.any()}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fusion des tables journal, price et influence\n",
        "Afin de simplifier les op\u00e9rations, on g\u00e9n\u00e8re une seule table r\u00e9sumant les diff\u00e9rentes informations des trois tables.\n",
        "On v\u00e9rifie d'abord si les valeurs des identifiants communs aux diff\u00e9rentes tables sont pr\u00e9sentes dans les tables \u00e0 \n",
        "fusionner. Pour cela, on v\u00e9rifie si les valeurs de l'attribut issn de la table influence sont existantes dans l'attribut\n",
        "issn dans la table journal. Suivant la m\u00eame id\u00e9e, on v\u00e9rifie les valeurs de l'attribut journal_id de price sont \n",
        "existantes dans l'attribut issn dans journal. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "check = influence['issn'].isin(journal['issn']).any()\n",
        "print(f\"Pas de valeur d'issn manquante dans journal par rapport \u00e0 influence : {check}\")\n",
        "\n",
        "check = price['journal_id'].isin(journal['issn']).any()\n",
        "print(f\"Pas de valeur d'issn manquante dans journal par rapport \u00e0 price : {check}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les attributs sur lesquels on se base pour la fusion sont effectivement bien repr\u00e9sent\u00e9s dans les tables \u00e0 fusionner, \n",
        "on peut donc envisager la fusion.\n",
        "\n",
        "On applique maintenant la fusion des trois tables en deux \u00e9tapes. D'abord, on fusionne la table influence dans la \n",
        "table journal. Ensuite, cette table r\u00e9sultante sera fusionn\u00e9e avec la table price.\n",
        "\n",
        "Les tables price et journal pr\u00e9sentent tous deux un attribut sous le nom 'url', cependant ils ne repr\u00e9sentent pas les \n",
        "m\u00eames attributs. Pour la table price, on renommera cet attribut en 'url_author', et pour la table journal, ce sera \n",
        "'url_journal'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "price = rename_df_headers(price, {\"journal_id\": \"issn\", \"url\": \"url_author\"})\n",
        "journal = rename_df_headers(journal, {\"url\": \"url_journal\"})\n",
        "\n",
        "temp = pd.merge(journal, influence, on='issn', how='outer')\n",
        "check = temp.apply(\n",
        "    lambda x: True if x['journal_name_x'] == x['journal_name_y'] or x['journal_name_y'] is np.nan else False, axis=1)\n",
        "print(f\"Non existence d'aberrances entre les attributs journal_name des tables journal et influence: {check.any()}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les attributs journal_name_x et journal_name_y pr\u00e9sentent les m\u00eames valeurs, on choisit d'\u00e9liminer arbitrairement \n",
        "l'attribut journal_name_y au profit de journal_name_x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp = temp.drop(columns=['journal_name_y'])\n",
        "temp = rename_df_headers(temp, {\"journal_name_x\": \"journal_name\"})\n",
        "\n",
        "print(f\"Valeurs uniques des attributs de temp pr\u00e9sentant {temp.shape[0]} objets:\\n\"\n",
        "      f\"{get_uniqueness_attributes(temp)}\")\n",
        "\n",
        "data = pd.merge(temp, price, on=['issn'], how='outer')\n",
        "data = get_df_duplicated_rows_dropped(data)\n",
        "\n",
        "print(f\"Valeurs uniques des attributs de data pr\u00e9sentant {data.shape[0]} objets:\\n\"\n",
        "      f\"{get_uniqueness_attributes(data)}\")\n",
        "print(f\"Ratio de valeurs vides pour les attributs de data:\\n\"\n",
        "      f\"{get_ratio_missing_values(data)}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On est effectivement assur\u00e9 que les valeurs de l'attribut issn de la nouvelle table data sont uniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. Y-a-t-il une corr\u00e9lation entre les cat\u00e9gories de journaux (attribut category) et les co\u00fbts de publication (attribut price)? Justifier la r\u00e9ponse.\n",
        "\n",
        "Afin de d\u00e9terminer s'il existe une corr\u00e9lation entre les cat\u00e9gories et l'attribut prix, on s'int\u00e9resse \u00e0 chaque \n",
        "cat\u00e9gorie une \u00e0 une et sa corr\u00e9lation propre avec l'attribut prix. \n",
        "\n",
        "Comme pr\u00e9cis\u00e9 dans la question 1, chaque objet peut avoir plusieurs valeurs de cat\u00e9gories. On observe diff\u00e9rents \n",
        "s\u00e9parateurs ('|', 'and', '.') entre les diff\u00e9rentes valeurs de cat\u00e9gories.\n",
        "Apr\u00e8s s\u00e9paration des diff\u00e9rentes cat\u00e9gories, on les convertit ensuite en one hot multivaleurs.\n",
        "\n",
        "Ainsi, on peut calculer la corr\u00e9lation cat\u00e9gorie par cat\u00e9gorie avec l'attribut prix. Pour cela, on ne consid\u00e8re que les \n",
        "objets pr\u00e9sentant la cat\u00e9gorie test\u00e9e et les valeurs de prix associ\u00e9es."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cat_labelled_data = data[data['category'].notna()]\n",
        "cat_data_to_predict = data[data['category'].isna()]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: category reductions\n",
        "cat_labelled_data = cat_labelled_data.copy()\n",
        "cat_labelled_data['category'] = cat_labelled_data['category'].str.replace(r'[\\.\\|&] | [\\.\\|&] | and ', '.', regex=True)\n",
        "category_dummies = cat_labelled_data['category'].str.get_dummies(sep='.')\n",
        "category_dummies_prefix = category_dummies.add_prefix('category_')\n",
        "print(f'Nombre de cat\u00e9gories apr\u00e8s s\u00e9paration: {category_dummies.shape[1]}')\n",
        "print(f'{category_dummies.columns}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il aurait \u00e9t\u00e9 pertinent de s'int\u00e9resser \u00e0 une r\u00e9duction par simplification des cat\u00e9gories, en effet on remarque que les\n",
        "cat\u00e9gories 'history' et 'history (general)' sont porteuses de la m\u00eame information et aurait pu \u00eatre r\u00e9sum\u00e9 sous la \n",
        "m\u00eame cat\u00e9gorie. Il est de m\u00eame pour plusieurs cat\u00e9gories. Ce travail est cependant fastidieux et je ne l'impl\u00e9menterai \n",
        "pas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cat_labelled_data = pd.concat([cat_labelled_data, category_dummies_prefix], axis=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "categories_correlation = {}\n",
        "\n",
        "for header in category_dummies_prefix.columns:\n",
        "    corr = cat_labelled_data[header].corr(cat_labelled_data['price'])\n",
        "    if abs(corr) > 0.1:\n",
        "        categories_correlation[header] = corr\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.bar(categories_correlation.keys(), categories_correlation.values())\n",
        "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
        "plt.title(f'Cat\u00e9gories pr\u00e9sentant des corr\u00e9lations fortes avec\\nl\\'attribut prix et leurs valeurs')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On remarque que certaines cat\u00e9gories pr\u00e9sentent effectement une l\u00e9g\u00e8re corr\u00e9lation avec l'attribut prix.\n",
        "(Les cat\u00e9gories pr\u00e9sentant une corr\u00e9lation inf\u00e9rieures \u00e0 0.1 ne sont pas incluses dans le graphe)\n",
        "Les cat\u00e9gories pr\u00e9sentant la plus forte corr\u00e9lation sont 'cell biology' et 'molecular'.\n",
        "Cette corr\u00e9lation remarqu\u00e9e est faible mais ne peut \u00eatre n\u00e9gligeable pour certaines cat\u00e9gories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. Construire un mod\u00e8le pour pr\u00e9dire les valeurs de cat\u00e9gorie de journaux manquantes de la fa\u00e7on la plus pr\u00e9cise possible (cela inclut la s\u00e9lection d\u2019attributs informatifs, le choix et le param\u00e9trage d\u2019un mod\u00e8le de classification, le calcul du score du mod\u00e8le, l\u2019application du mod\u00e8le pour pr\u00e9dire les cat\u00e9gories manquantes). Justifier les choix effectu\u00e9s.\n",
        "\n",
        "Dans le but de pr\u00e9dire les cat\u00e9gories de journaux, on doit s'int\u00e9resser \u00e0 plusieurs attributs qui pourraient nous\n",
        "aider. Le nom du journal pourrait inclure certains mots-cl\u00e9s qui pourraient s'apparenter aux cat\u00e9gories du journal.\n",
        "Le nom de l'\u00e9diteur pourrait \u00e9galement apporter de l'information sur les cat\u00e9gories.\n",
        "Cependant, ces deux attributs sont des donn\u00e9es textuelles non cat\u00e9gorielles tr\u00e8s inconsistantes. Afin de pouvoir en \n",
        "sortir quelque chose, une solution serait de calculer la similarit\u00e9 de ces valeurs avec le nom de chacune des cat\u00e9gories\n",
        "que l'on a pu d\u00e9terminer dans la question pr\u00e9c\u00e9dente. On utilise alors la classe Sequence Matcher sur journal_name et \n",
        "pub_name avec le nom de chacune des cat\u00e9gories et inscrit chacun des scores au sein d'un nouvel attribut pour la table \n",
        "cat_labelled_data.\n",
        "\n",
        "A la question pr\u00e9c\u00e9dente, on a pu trouver une corr\u00e9lation l\u00e9g\u00e8re entre certaines cat\u00e9gories et l'attribut prix. On peut \n",
        "donc envisager de prendre en compte le param\u00e8tre prix.\n",
        "\n",
        "Les informations de citation du journal pourraient \u00e9galement se r\u00e9v\u00e9ler porteuses d'informations, on consid\u00e8re alors \n",
        "l'utilisation de l'attribut avg_cites_per_paper qui r\u00e9sume ces informations.\n",
        "\n",
        "On peut consid\u00e9rer \u00e9galement que certaines cat\u00e9gories ont plus d'influence de mani\u00e8re globale que d'autres, on choisit\n",
        "alors d'utiliser \u00e9galement l'attribut proj_ai."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cat_labelled_data = cat_labelled_data[cat_labelled_data['price'].notna()]\n",
        "headers = ['avg_cites_per_paper', 'proj_ai', 'price']\n",
        "\n",
        "# \u00e9limination des objets pr\u00e9sentant des valeurs nulles dans les attributs d'int\u00e9r\u00eats\n",
        "cat_labelled_data = cat_labelled_data.dropna(axis=0, subset=headers)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# cr\u00e9ation des attributs correspondant au score de journal_name et pub_name avec chaque cat\u00e9gorie\n",
        "for header in tqdm(category_dummies.columns):\n",
        "    cat_labelled_data['jn_' + header] = cat_labelled_data.apply(partial(get_score_sequence_matching, c1='journal_name',\n",
        "                                                                        category=header), axis=1)\n",
        "    cat_labelled_data['pn_' + header] = cat_labelled_data.apply(partial(get_score_sequence_matching, c1='pub_name',\n",
        "                                                                        category=header), axis=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cat_labelled_data = cat_labelled_data.drop(columns=['category'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# extraction des noms des attributs score pour journal_name et pub_name\n",
        "jn_sm_headers = cat_labelled_data.filter(like='jn_').columns.to_list()\n",
        "pn_sm_headers = cat_labelled_data.filter(like='pn_').columns.to_list()\n",
        "\n",
        "# ajout des attributs score aux attributs d'int\u00e9r\u00eats pour le mod\u00e8le\n",
        "attributes_of_interest = headers\n",
        "attributes_of_interest.extend(jn_sm_headers)\n",
        "attributes_of_interest.extend(pn_sm_headers)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrainement\n",
        "On s'int\u00e9resse \u00e0 un syst\u00e8me de classification ayant la capacit\u00e9 de pouvoir pr\u00e9duire des labels multiples.\n",
        "Pour cela, on utilise la m\u00e9thode MultiOutputClassifier de sklearn afin qui consiste \u00e0 adapter un classificateur par\n",
        "cible.\n",
        "A partir de l\u00e0, on a pu essayer plusieurs types de classification, la meilleure s'est r\u00e9v\u00e9l\u00e9e \u00eatre un mod\u00e8le Random\n",
        "Forest. Etant donn\u00e9 que l'on dispose de donn\u00e9es num\u00e9riques et cat\u00e9gorielles, la performance d'un Random Forest n'est pas\n",
        "\u00e9tonnante. Aussi, le fait qu'un mod\u00e8le de ce type ait une capacit\u00e9 \u00e0 ne pas sur-apprendre de trop permet de g\u00e9n\u00e9raliser \n",
        "bien sur nos donn\u00e9es. \n",
        "\n",
        "On utilise la m\u00e9thode GridSearchCV afin de faire une recherche d'hyperparam\u00e8tres, celle-ci est assez succinte pour le \n",
        "confort de compilation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parameters_grid_search = {\n",
        "    \"estimator__max_depth\": np.linspace(14, 16, 4, dtype=int),\n",
        "    \"estimator__n_estimators\": np.linspace(100, 200, 4, dtype=int)\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "classifier = MultiOutputClassifier(clf, n_jobs=-1)\n",
        "category_clf = GridSearchCV(classifier, parameters_grid_search, verbose=1, n_jobs=-1, cv=2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cat_labelled_data[headers],\n",
        "                                                    cat_labelled_data[category_dummies_prefix.columns],\n",
        "                                                    test_size=0.2, random_state=42)\n",
        "X_train = X_train[attributes_of_interest]\n",
        "X_test = X_test[attributes_of_interest]\n",
        "y_train = y_train.to_numpy()\n",
        "\n",
        "category_clf.fit(X_train, y_train)\n",
        "train_score = category_clf.score(X_train, y_train)\n",
        "print(f'Score d\\'entra\u00eenement: {train_score}')\n",
        "\n",
        "test_predictions = category_clf.predict(X_test)\n",
        "test_score = category_clf.score(X_test, y_test)\n",
        "print(f'Score de test: {test_score}')\n",
        "print(f\"Meilleurs param\u00e8tres trouv\u00e9s : {category_clf.best_params_}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On conclut ainsi que le classificateur Random Forest ayant une profondeur maximale de 16 pr\u00e9sente des r\u00e9sultats se\n",
        "trouve \u00eatre le plus performant.\n",
        "Aussi, on se trouve en pr\u00e9sence de r\u00e9sultats tr\u00e8s performants, \u00e9tant donn\u00e9 qu'on dispose de 88 labels \u00e0 pr\u00e9dire, soient\n",
        "les cat\u00e9gories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pr\u00e9dictions\n",
        "On effectue maintenant les pr\u00e9dictions sur les objets pr\u00e9sentant les cat\u00e9gories manquantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "headers = ['avg_cites_per_paper', 'proj_ai', 'price']\n",
        "cat_data_to_predict = cat_data_to_predict.dropna(axis=0, subset=headers)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Comme lors de la partie entrainement, on calcule le score de Sequence Matcher entre les attributs journal_name et\n",
        "# pub_name et chacune des cat\u00e9gories\n",
        "for header in tqdm(category_dummies.columns):\n",
        "    cat_data_to_predict['jn_' + header] = cat_data_to_predict.apply(partial(get_score_sequence_matching,\n",
        "                                                                            c1='journal_name', category=header), axis=1)\n",
        "    cat_data_to_predict['pn_' + header] = cat_data_to_predict.apply(partial(get_score_sequence_matching, c1='pub_name',\n",
        "                                                                            category=header), axis=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "predictions = pd.DataFrame(category_clf.predict(cat_data_to_predict[attributes_of_interest]))\n",
        "predictions.columns = category_dummies_prefix.columns"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# On r\u00e9pertorie le nombre de cat\u00e9gories pr\u00e9dites\n",
        "count_categories = {}\n",
        "for header in predictions.columns:\n",
        "    nb = predictions[header].sum()\n",
        "    if nb >= 1:\n",
        "        count_categories[header] = nb"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.bar(count_categories.keys(), count_categories.values())\n",
        "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
        "plt.title(f'Somme des cat\u00e9gories pr\u00e9dites par le mod\u00e8le')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ajout des pr\u00e9dictions des cat\u00e9gories \u00e0 leurs objets respectifs dans la table cat_data_to_predict\n",
        "predictions = predictions.set_index(cat_data_to_predict.index.copy())\n",
        "for header in predictions.columns:\n",
        "    cat_data_to_predict[header] = predictions[header]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 3: R\u00e9gression-clustering\n",
        "## A. Supprimer tous les attributs ayant plus de 50% de donn\u00e9es manquantes.\n",
        "\n",
        "On \u00e9tablit les attributs pr\u00e9sentant 50% de donn\u00e9es manquantes \u00e0 \u00e9liminer selon les 3 tables originales (journal, price\n",
        "et influence).\n",
        "\n",
        "Cependant, on utilise nos donn\u00e9es d\u00e9j\u00e0 travaill\u00e9es qui sont dans les tables cat_labelled_data et cat_data_to_predict.\n",
        "Aussi, au vu des bons r\u00e9sultats de pr\u00e9dictions du mod\u00e8le de classification pour les cat\u00e9gories, on peut se permettre \n",
        "d'utiliser les objets pr\u00e9dits pour la suite du travail. \n",
        "\n",
        "On \u00e9tablit alors une nouvelle table, nomm\u00e9e data, pr\u00e9sentant l'ensemble des donn\u00e9es, originales et pr\u00e9dites, et on peut\n",
        "y \u00e9liminer les attributs pr\u00e9sentant plus de 50% de valeurs manquantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f'Attributs \u00e0 \u00e9liminer de la table journal: {get_empty_attribute_to_remove(journal)}')\n",
        "print(f'Attributs \u00e0 \u00e9liminer de la table price: {get_empty_attribute_to_remove(price)}')\n",
        "print(f'Attributs \u00e0 \u00e9liminer de la table influence: {get_empty_attribute_to_remove(influence)}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = cat_labelled_data.append(cat_data_to_predict, sort=False)\n",
        "data = data.drop(columns=['url_journal', 'influence_id', 'url_author', 'license'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. Construire un mod\u00e8le pour pr\u00e9dire le co\u00fbt actuel de publication (attribut \u00abprice\u00bb) \u00e0 partir des autres attributs  (cela inclut la s\u00e9lection d\u2019attributs informatifs, le choix et le param\u00e9trage d\u2019un mod\u00e8le de r\u00e9gression, le calcul du  score du mod\u00e8le, l\u2019application du mod\u00e8le pour pr\u00e9dire les co\u00fbts).Justifier les choix effectu\u00e9s. Lister les 10 revues qui s\u2019\u00e9cartent le plus (en + ou -) de la valeur pr\u00e9dite.\n",
        "\n",
        "### S\u00e9lection des attributs\n",
        "\n",
        "L'attribut date_stamp \u00e9tablissant la date \u00e0 laquelle le co\u00fbt de publication a \u00e9t\u00e9 mesur\u00e9 semble int\u00e9ressant. On d\u00e9cide \n",
        "de garder seulement l'ann\u00e9e car une pr\u00e9cision plus importante semble peu pertinente.\n",
        "\n",
        "Comme vu pr\u00e9c\u00e9demment l'attribut price pr\u00e9sente seulement une faible corr\u00e9lation aux cat\u00e9gories d'une revue, cependant\n",
        "certaines cat\u00e9gories sortaient du lot. Les cat\u00e9gories sous la forme de vecteur one hot multivaleurs sont donc \u00e0 \n",
        "envisager.\n",
        "\n",
        "L'information d'un journal sur son hybridicit\u00e9 est \u00e9galement un facteur important sur son co\u00fbt de publication. \n",
        "\n",
        "L'attribut avg_cites_per_paper, pr\u00e9sentant le rapport entre les attributs citation_count_sum et paper_count_sum, r\u00e9v\u00e8le\n",
        "\u00e0 quel point la revue est cit\u00e9 par papier. Il ne serait pas \u00e9tonnant que cette information soit li\u00e9e au prix de \n",
        "publication d'articles au sein de la revue. \n",
        "Les attributs citation_count_sum et paper_count_sum ne sont pas n\u00e9cessaires car r\u00e9sum\u00e9s dans l'attribut \n",
        "avg_cites_per_paper.\n",
        "\n",
        "L'attribut proj_ai pr\u00e9sente l'influence des articles d'une revue est \u00e9galement important et on pourrait sans soucis \n",
        "imaginer que plus la valeur d'influence est \u00e9lev\u00e9e, plus le co\u00fbt de publication dans une revue serait important.\n",
        "N\u00e9anmoins, l'attribut proj_ai_year, pr\u00e9sentant toujours la m\u00eame valeur (2015) ne nous apporterait aucune information \n",
        "sur le jeu de donn\u00e9es. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data['year_price'] = pd.DatetimeIndex(data['date_stamp']).year"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "attributes_of_interest = ['year_price', 'avg_cites_per_paper', 'proj_ai', 'is_hybrid', 'price']\n",
        "attributes_of_interest.extend(category_dummies_prefix.columns)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "price_labelled_data = data[attributes_of_interest]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On construit un mod\u00e8le de r\u00e9gression Random Forest. Ce type de mod\u00e8le ayant bien march\u00e9 pour nos donn\u00e9es, lors de la \n",
        "g\u00e9n\u00e9ration d'un mod\u00e8le de classification pour les cat\u00e9gories, il est pertinent de r\u00e9utiliser ce type de mod\u00e8le.\n",
        "Comme pr\u00e9c\u00e9demment, on effectue une recherche d'hyperparam\u00e8tres avec la m\u00e9thode GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "best_model = {'depth': 0, 'score': 0, 'model': None}\n",
        "parameters_grid_search = {\n",
        "    \"max_depth\": np.linspace(13, 18, 5, dtype=int),\n",
        "    \"n_estimators\": np.linspace(200, 400, 10, dtype=int)\n",
        "}\n",
        "\n",
        "regr = RandomForestRegressor()\n",
        "price_estim = GridSearchCV(regr, parameters_grid_search, verbose=1, n_jobs=-1, cv=2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(price_labelled_data.drop(columns='price'),\n",
        "                                                    price_labelled_data['price'],\n",
        "                                                    test_size=0.2, random_state=42)\n",
        "price_estim.fit(X_train, y_train)\n",
        "train_score = price_estim.score(X_train, y_train)\n",
        "print(f'Score d\\'entra\u00eenement: {train_score}')\n",
        "\n",
        "test_predictions = price_estim.predict(X_test)\n",
        "test_score = price_estim.score(X_test, y_test)\n",
        "print(f'Score de test: {test_score}')\n",
        "print(f\"Meilleurs param\u00e8tres trouv\u00e9s : {price_estim.best_params_}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le mod\u00e8le Random Forest avec un profondeur maximale de 13 se r\u00e9v\u00e8le \u00eatre le meilleur avec un score de test aux alentours\n",
        "de 77%. Cela se r\u00e9v\u00e8le \u00eatre un tr\u00e8s bon mod\u00e8le."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Application du mod\u00e8le\n",
        "On applique ce mod\u00e8le sur l'ensemble de nos donn\u00e9es (entrainement et test) afin de d\u00e9terminer quels sont les objets dont\n",
        "les pr\u00e9dictions sont les moins bonnes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictions = pd.DataFrame(price_estim.predict(price_labelled_data.drop(columns='price')))\n",
        "predictions = predictions.set_index(data.index.copy())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "difference_pred_real = dict()\n",
        "for index, p in predictions.iterrows():\n",
        "    difference_pred_real[data['journal_name'][index]] = abs(p[0] - data['price'][index])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f'Nom des 10 revues pr\u00e9sentant les plus gros \u00e9carts entre leur pr\u00e9diction de co\u00fbt et la r\u00e9alit\u00e9:\\n'\n",
        "      f'\\nNom: diff\u00e9rence')\n",
        "worst_predictions = np.array(heapq.nlargest(10, difference_pred_real, key=difference_pred_real.get))\n",
        "worst_predictions_values = []\n",
        "for p in worst_predictions:\n",
        "    worst_predictions_values.append(difference_pred_real.get(p))\n",
        "    print(f'{p} : {difference_pred_real.get(p)}')\n",
        "\n",
        "worst_predictions = np.vstack([worst_predictions, worst_predictions_values])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les 10 revues o\u00f9 les pr\u00e9dictions s'\u00e9loignent le plus de la r\u00e9alit\u00e9 pr\u00e9sentent des diff\u00e9rences de pr\u00e9dictions tr\u00e8s \n",
        "importantes (+ de 2000 dollars). Cela peut s'expliquer assez simplement avec le fait que de nombreuses valeurs de co\u00fbts de \n",
        "publication sont \u00e0 0 dollar alors qu'un nombre \u00e9galement important sont \u00e0 3000 dollars.\n",
        "Ce grand \u00e9cart n'est donc pas tr\u00e8s r\u00e9v\u00e9lateur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. Construire un mod\u00e8le pour grouper les revues selon le co\u00fbt actuel de publication (attribut \"price\") et le score d'influence (attribut \"proj_ai\") (cela inclut la d\u00e9termination du nombre de clusters, le choix et le param\u00e9trage d'un mod\u00e8le de clustering, l'application du mod\u00e8le pour trouver les clusters). Justifier les choix.\n",
        "\n",
        "Etant donn\u00e9 que les mesures de distance vont \u00eatre importantes pour d\u00e9terminer les clusters, il serait pertinent de \n",
        "normaliser et centraliser les donn\u00e9es.\n",
        "Nos donn\u00e9es sont tr\u00e8s regroup\u00e9es en un bloc et pr\u00e9sente quelques donn\u00e9es que l'on pourrait qualifier de donn\u00e9es \n",
        "aberrantes.\n",
        "On essaie alors diff\u00e9rentes m\u00e9thodes de clustering qui se r\u00e9v\u00e8lent \u00eatre performantes sur des donn\u00e9es peu s\u00e9par\u00e9es en \n",
        "clusters bien d\u00e9finis, soient Agglomerative Clustering, DBSCAN et Gaussian Mixture. \n",
        "Aussi, on essaie \u00e9galement KMeans afin pour se donner une r\u00e9f\u00e9rence, n\u00e9anmoins celui-ci devrait \u00eatre moins bon que les\n",
        "autres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "attributes_of_interest = ['price', 'proj_ai']\n",
        "data_for_clustering = data[attributes_of_interest]\n",
        "norm_data_for_clustering = StandardScaler().fit_transform(data_for_clustering)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "estimators = {'K Means 4 clusters': KMeans(n_clusters=4, random_state=42),\n",
        "              'Agglomerative Clustering 4 clusters, ward': AgglomerativeClustering(n_clusters=4, linkage='ward'),\n",
        "              'DBSCAN': DBSCAN(),\n",
        "              'GaussianMixture 3 clusters, diag': GaussianMixture(n_components=3, covariance_type='diag')}\n",
        "\n",
        "for name, estimator in estimators.items():\n",
        "    plt.figure()\n",
        "    y_pred = estimator.fit_predict(norm_data_for_clustering)\n",
        "    plt.scatter(data_for_clustering['price'], data_for_clustering['proj_ai'], c=y_pred)\n",
        "    plt.title(name)\n",
        "    plt.show()\n",
        "\n",
        "    if name == 'DBSCAN':\n",
        "        best_estimator_pred = y_pred"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tout d'abord, on remarque que K Means (4 clusters) et Agglomerative Clustering (4 clusters) effectuent quasiment \n",
        "le m\u00eame regroupement. Ces deux m\u00e9thodes ne permettent pas de vraiment faire ressortir les clusters tels qu'on les \n",
        "voient et les divisent. \n",
        "\n",
        "Gaussian Mixture (3 clusters) pr\u00e9sente toutes les 'donn\u00e9es extr\u00eames' au sein d'un m\u00eame cluster, puis trouve un autre\n",
        "cluster pr\u00e8s de l'origine. Le cluster des 'donn\u00e9es extr\u00eames' ne semble pas pertinent. \n",
        "\n",
        "La m\u00e9thode DBSCAN repr\u00e9sente les donn\u00e9es extr\u00eames comme aberrantes et sp\u00e9cifie 3 clusters. Un des clusters regroupe la\n",
        "majorit\u00e9 des donn\u00e9es qui sont tr\u00e8s regroup\u00e9s. Les 2 autres clusters sont des donn\u00e9es un peu plus \u00e9parses avec quelques\n",
        "points mais n\u00e9anmoins non n\u00e9gliables. On peut donc conclure que DBSCAN et sa repr\u00e9sentation en 3 clusters donnent des\n",
        "clusters probants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. Pr\u00e9senter des statistiques descriptives des clusters obtenus, et lister les revues du meilleur cluster en termes  en termes de rapport moyen: score d'influence / co\u00fbt de publication. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On a conclue \u00e0 la question pr\u00e9c\u00e9dente que la m\u00e9thode de clustering la plus probante est DBSCAN. On utilise alors les pr\u00e9dictions de clusters trouv\u00e9s par DBSCAN afin de poursuivre notre \u00e9tude sur les clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_for_clustering = data_for_clustering.copy()\n",
        "data_for_clustering['cluster_predicted'] = best_estimator_pred"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stats_clusters = dict()\n",
        "for c in data_for_clustering['cluster_predicted'].unique():\n",
        "    print(f'\\nCluster {c}:')\n",
        "    temp = data_for_clustering[data_for_clustering['cluster_predicted'] == c]\n",
        "    print(f\"{temp[['price', 'proj_ai']].describe()}\")\n",
        "\n",
        "    if temp['price'].mean() == 0:\n",
        "        ratio = temp['proj_ai'].mean() / 0.00001\n",
        "    else:\n",
        "        ratio = temp['proj_ai'].mean() / temp['price'].mean()\n",
        "    print(f'Rapport moyen entre le score d\\'influence et les co\u00fbts de publication: {ratio}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le cluster pr\u00e9sentant le meilleur rapport moyen entre le score d'influence et les co\u00fbts de publication est celui nomm\u00e9\n",
        "1, pr\u00e9sentant des co\u00fbts de publication nuls et un score d'influence suffisamment \u00e9lev\u00e9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Liste des revues dans le cluster ayant le meilleur rapport co\u00fbts de publication et score d'influence:\"\n",
        "      f\"{data[data_for_clustering['cluster_predicted'] == 1][['journal_name', 'pub_name']]}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}