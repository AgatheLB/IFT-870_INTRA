{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# leba3207\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import difflib\n",
    "from functools import partial"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des donnÃ©es des diffÃ©rents fichiers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "data_folder = 'data/'\n",
    "\n",
    "journal_file = 'api_journal11-13-17.csv'\n",
    "price_file = 'api_price11-13-17.csv'\n",
    "influence_file = 'estimated-article-influence-scores-2015.csv'\n",
    "\n",
    "journal = pd.read_csv(data_folder + journal_file, sep=',', encoding='latin1')\n",
    "price = pd.read_csv(data_folder + price_file, sep=',', index_col=0)\n",
    "influence = pd.read_csv(data_folder + influence_file, sep=',', index_col=0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def get_uniqueness_attributes(table):\n",
    "    return table.nunique(axis=0)\n",
    "\n",
    "\n",
    "def get_ratio_missing_values(table):\n",
    "    return table.isnull().sum() * 100 / len(table)\n",
    "\n",
    "\n",
    "def get_unique_values_of_attribute(table, header):\n",
    "    return table[header].unique()\n",
    "\n",
    "\n",
    "def lowercase_columns(table, headers):\n",
    "    for header in headers:\n",
    "        table[header] = table[header].str.lower()\n",
    "\n",
    "\n",
    "# TODO: include headers specification\n",
    "def get_df_duplicated_rows_dropped(table):\n",
    "    return table.drop_duplicates()\n",
    "\n",
    "\n",
    "def plot_categories_frequency(table, header):\n",
    "    fig, ax = plt.subplots()\n",
    "    table[header].value_counts()[0:5].plot(ax=ax, kind='bar')\n",
    "    plt.title(f'FrÃ©quence d\\'apparition des catÃ©gories de l\\'attribut {header}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_mean_price_per_year():\n",
    "    mean_price_per_year = {}\n",
    "    for index, p in price.iterrows():\n",
    "        year = p['date_stamp'].year\n",
    "        if year in mean_price_per_year:\n",
    "            mean_price_per_year[year] += p['price']\n",
    "        else:\n",
    "            mean_price_per_year[year] = p['price']\n",
    "\n",
    "    for year, value in mean_price_per_year.items():\n",
    "        mean_price_per_year[year] /= len(price[price['price'] != 0])\n",
    "    return {k: v for k, v in sorted(mean_price_per_year.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "\n",
    "def rename_df_headers(table, dict_headers):\n",
    "    return table.rename(columns=dict_headers)\n",
    "\n",
    "\n",
    "def get_score_sequence_matching(s, c1, c2):\n",
    "    return difflib.SequenceMatcher(None, s[c1], s[c2]).ratio()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question 1: Exploration-Description\n",
    "## PrÃ©senter une description de chacun des attributs des 3 tables, avec des graphiques pour la visualisation des \n",
    "statistiques descriptives au besoin.\n",
    "\n",
    "### Table journal"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO: visualisations\n",
    "# frÃ©quence des valeurs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(journal.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "issn: identifiant du journal\n",
    "Les valeurs de cet attribut semblent suivre un format particulier tel que: 4 digits - 4 digits\n",
    "\n",
    "journal_name: nom textuel du journal\n",
    "Les valeurs sont textuelles, ne suivant pas de valeurs catÃ©gorielles particuliÃ¨re Ã  priori.\n",
    "\n",
    "pub_name: nom de l'Ã©diteur du journal\n",
    "Les valeurs sont textuelles, ne suivant pas de valeurs catÃ©gorielles particuliÃ¨re Ã  priori.\n",
    "\n",
    "is_hybrid: indique si le journal est hybride, ce qui signifie que c'est une revue sur abonnement dont certains articles\n",
    "sont en libre accÃ¨s, comme l'indique le site http://flourishoa.org/about.\n",
    "\n",
    "category: renseigne sur la/les catÃ©gorie(s) des sujets abordÃ©s par le journal \n",
    "Les valeurs sont textuelles et sont catÃ©gorielles. Chaque objet peut possÃ©der des valeurs multiples pour cet attribut. La sÃ©paration entre les diffÃ©rentes valeurs semblent\n",
    "Ãªtre inconsistante.\n",
    "\n",
    "url: indique l'adresse url du site du journal\n",
    "\n",
    "\n",
    "Les attributs journal_name, pub_name et category Ã©tant des donnÃ©es textuelles trÃ¨s inconsistantes, je dÃ©cide avant tout\n",
    "traitement et Ã©tude supplÃ©mentaire de transformer les valeurs en minuscule pour limiter au maximum l'inconsistence.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "lowercase_columns(journal, ['journal_name', 'pub_name', 'category'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(f\"Valeurs uniques des attributs de journal:\\n\"\n",
    "      f\"{get_uniqueness_attributes(journal)}\")\n",
    "print(f\"Ratio de valeurs vides pour les attributs de journal:\\n\"\n",
    "      f\"{get_ratio_missing_values(journal)}\")\n",
    "\n",
    "print(f\"Valeurs possibles pour l'attribut is_hybrid de journal:\\n\"\n",
    "      f\"{get_unique_values_of_attribute(journal, 'is_hybrid')}\")\n",
    "print(f\"Valeurs possibles pour l'attribut category de journal:\\n\"\n",
    "      f\"{get_unique_values_of_attribute(journal, 'category')}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs category et url prÃ©sentent un nombre consÃ©quent de valeurs manquantes.\n",
    "L'attribut issn prÃ©sente des valeurs uniques pour chacun de ses objets.\n",
    "\n",
    "On remarque qu'il existe uniquement deux valeurs pour l'attribut is_hybrid (soit 1 soit 0). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(f\"Valeurs possibles de pub_name quand is_hybrid vaut 1:\\n\"\n",
    "      f\"{journal[journal['is_hybrid'] == 1]['pub_name'].unique()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "plot_categories_frequency(journal, 'pub_name')\n",
    "plot_categories_frequency(journal, 'category')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table price"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(price.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price: information du prix d'une publication pour le journal associÃ© Ã  une date prÃ©cise, en dollar US\n",
    "Si celui-ci est Ã  0, on peut coompendre que celui-ci est gratuit\n",
    "\n",
    "date_stamp: horodatage de l'information de prix d'une publication, en format annÃ©es-mois-jour\n",
    "\n",
    "journal_id: identifiant du journal\n",
    "Les valeurs semblent suivre consistantement un format du type: 4 digits - 4 digits\n",
    "\n",
    "influence_id: identifiant de l'influence\n",
    "Les valeurs suivent un format 4 digits.\n",
    "\n",
    "url: indique l'adresse url du site de l'auteur\n",
    "\n",
    "license: indique le type de license utilisÃ© par le journal pour les diffÃ©rents articles utilisÃ©s.\n",
    "\n",
    "\n",
    "On convertit l'attribut date_stamp en type date."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "price['date_stamp'] = pd.to_datetime(price['date_stamp'], errors='coerce', format='%Y-%m-%d')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(f\"Valeurs uniques des attributs de price:\\n\"\n",
    "      f\"{get_uniqueness_attributes(price)}\")\n",
    "print(f\"Ratio de valeurs vides pour les attributs de price:\\n\"\n",
    "      f\"{get_ratio_missing_values(price)}\")\n",
    "\n",
    "print(f\"Exemples de valeurs possibles pour l'attribut influence_id de price:\\n\"\n",
    "      f\"{get_unique_values_of_attribute(price, 'influence_id')[1:8]}\")\n",
    "print(f\"Valeurs possibles pour l'attribut license de price:\\n\"\n",
    "      f\"{get_unique_values_of_attribute(price, 'license')}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs influence_id, url et license prÃ©sentent une majoritÃ© de valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "mean_price_per_year = get_mean_price_per_year()\n",
    "\n",
    "plt.bar(range(len(mean_price_per_year)), mean_price_per_year.values())\n",
    "plt.xticks(range(len(mean_price_per_year)), mean_price_per_year.keys())\n",
    "plt.title(\"Moyenne par annÃ©e des prix des publications\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table influence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(influence.head())\n",
    "\n",
    "# TODO: proj_ai moyenne"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "journal_name: nom textuel du journal\n",
    "Les valeurs sont textuelles, ne suivant pas de valeurs catÃ©gorielles particuliÃ¨re Ã  priori.\n",
    "\n",
    "issn: identifiant du journal\n",
    "Les valeurs de cet attribut semblent suivre un format particulier tel que: 4 digits - 4 digits\n",
    "\n",
    "citation_count_sum: indique le nombre de citations du jounal\n",
    "\n",
    "paper_count_sum: indique le nombre de citations des articles du jounal\n",
    "\n",
    "avg_cites_per_paper: indique la moyenne des citations par papier qui sont contenus du journal\n",
    "\n",
    "proj_ai: information sur le score d'influence des articles du journal\n",
    "\n",
    "proj_ai_year: spÃ©cification de l'annÃ©e oÃ¹ l'information sur le score d'influence des articles du journal a Ã©tÃ© Ã©tablie"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(f\"Valeurs uniques des attributs de influence:\\n\"\n",
    "      f\"{get_uniqueness_attributes(influence)}\")\n",
    "print(f\"Ratio de valeurs vides pour les attributs de influence:\\n\"\n",
    "      f\"{get_ratio_missing_values(influence)}\")\n",
    "\n",
    "print(f\"Valeurs possibles pour l'attribut proj_ai_year de influence:\\n\"\n",
    "      f\"{get_unique_values_of_attribute(influence, 'proj_ai_year')}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'attribut proj_ai_year ne prÃ©sentant qu'une seule valeur nous indique que les valeurs de l'attribut proj_ai ont toutes\n",
    "Ã©tÃ© Ã©tablies Ã  la mÃªme pÃ©riode. \n",
    "\"\"\"\n",
    "\n",
    "# TODO: proj_ai sum in function of journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: PrÃ©traitement-ReprÃ©sentation\n",
    "## A. Effectuer un prÃ©traitement des donnÃ©es pour supprimer les duplications et corriger les incohÃ©rences sâ€™il y en a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table journal\n",
    "Dans un premier temps, on Ã©limine les objets prÃ©sentant des objets dupliquÃ©s sur tous les attributs.\n",
    "On se base sur l'attribut issn qui devrait Ãªtre unique pour chaque objet de la table, on vÃ©rifie son unicitÃ©."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "nb = len(journal)\n",
    "journal = get_df_duplicated_rows_dropped(journal)\n",
    "print(f\"Nombre d'objets dupliquÃ©s Ã©liminÃ©s dans journal: {nb - len(journal)}\")\n",
    "\n",
    "check = np.logical_not(journal['issn'].duplicated().any())\n",
    "print(f\"UnicitÃ© de l'attribut issn dans la table journal: {check}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table price\n",
    "Etant donnÃ© que les index Ã©taient fournis dans le fichier original et qu'on les utilise afin d'indexer nos objets, \n",
    "on vÃ©rifie qu'il n'existe pas de duplicata.\n",
    "\n",
    "Ensuite, on Ã©limine les objets prÃ©sentant des objets dupliquÃ©s sur tous les attributs.\n",
    "Dans un second temps, dans la table price, les objets se doivent d'Ãªtre uniques selon deux attributs, date_stamp et\n",
    "journal_id. S'ils ne le sont pas, alors ceux sont des objets dupliquÃ©s."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "check = np.logical_not(price.index.duplicated().any())\n",
    "print(f\"UnicitÃ© des indexes de la table price: {check}\")\n",
    "\n",
    "nb = len(price)\n",
    "price = get_df_duplicated_rows_dropped(price)\n",
    "print(f\"Nombre d'objets dupliquÃ©s Ã©liminÃ©s dans price: {nb - len(price)}\")\n",
    "\n",
    "duplicated_rows = price[price[['date_stamp', 'journal_id']].duplicated(keep=False)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe des duplicata ambigus que l'on dÃ©cide de traiter un Ã  un.\n",
    "\n",
    "Premier cas: un des objets prÃ©sente un prix nul, on dÃ©cide de choisir de l'Ã©liminer au profit de l'autre."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(duplicated_rows.iloc[0].fillna(0) == duplicated_rows.iloc[1].fillna(0))\n",
    "price = price.drop(duplicated_rows.index.values[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeuxiÃ¨me cas: leur valeur du prix est diffÃ©rente d'un lÃ©ger Ã©cart, on dÃ©cide de garder la deuxiÃ¨me de maniÃ¨re\n",
    "arbitraire"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(duplicated_rows.iloc[40].fillna(0) == duplicated_rows.iloc[41].fillna(0))\n",
    "price = price.drop(duplicated_rows.index.values[40])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TroisiÃ¨me cas: seule la valeur de license est diffÃ©rente, on dÃ©cide de garder la premiÃ¨re de maniÃ¨re arbitraire."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "for i in range(3, 39, 2):\n",
    "    price = price.drop(duplicated_rows.index.values[i])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table influence\n",
    "Etant donnÃ© que les index Ã©taient fournis dans le fichier original et qu'on les utilise afin d'indexer nos objets, \n",
    "on vÃ©rifie qu'il n'existe pas de duplicata.\n",
    "\n",
    "On se base sur l'attribut issn qui devrait Ãªtre unique pour chaque objet de la table, on vÃ©rifie son unicitÃ©."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "nb = len(influence)\n",
    "influence = get_df_duplicated_rows_dropped(influence)\n",
    "print(f\"Nombre d'objets dupliquÃ©s Ã©liminÃ©s dans influence: {nb - len(influence)}\")\n",
    "\n",
    "check = np.logical_not(influence['issn'].duplicated().any())\n",
    "print(f\"UnicitÃ© de l'attribut issn dans la table influence: {check}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs citation_count_sum, paper_count_sum, avg_cites_per_paper et proj_ai prÃ©sentent des valeurs nulles que l'on\n",
    "dÃ©cide d'attribuer Ã  0."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# headers = ['citation_count_sum', 'paper_count_sum', 'avg_cites_per_paper', 'proj_ai']\n",
    "# for header in headers:\n",
    "#     influence[header] = influence[header].fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "Afin de simplifier les opÃ©rations, on gÃ©nÃ¨re une seule table reprenant les informations des trois tables.\n",
    "On vÃ©rifie d'abord si les identifiants communs aux diffÃ©rentes tables sont prÃ©sentes dans les tables Ã  merger.\n",
    "En premier, on vÃ©rifie si les valeurs de l'attribut issn de influence sont existantes dans l'attribut du mÃªme nom \n",
    "dans journal.\n",
    "De mÃªme, on vÃ©rifie les valeurs de l'attribut journal_id de price sont existantes dans l'attribut issn dans journal. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "check = influence['issn'].isin(journal['issn']).any()\n",
    "print(f\"Pas de valeur d'issn manquante dans journal par rapport Ã  influence : {check}\")\n",
    "\n",
    "check = price['journal_id'].isin(journal['issn']).any()\n",
    "print(f\"Pas de valeur d'issn manquante dans journal par rapport Ã  price : {check}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique maintenant le merge des trois tables en deux Ã©tapes. D'abord, on merge influence dans journal, puis price\n",
    "est ensuite mergÃ© dans le rÃ©sultat du premier merge."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "price = rename_df_headers(price, {\"journal_id\": \"issn\", \"url\": \"url_autor\"})\n",
    "journal = rename_df_headers(journal, {\"url\": \"url_journal\"})\n",
    "\n",
    "temp = pd.merge(journal, influence, on='issn', how='outer')\n",
    "check = len(temp[temp['journal_name_x'] != temp['journal_name_y']])\n",
    "print(f\"Nombre d'aberrances entre les valeurs journal_name des tables journal et influence: {check}\")\n",
    "temp = temp.drop(columns=['journal_name_y'])\n",
    "temp = rename_df_headers(temp, {\"journal_name_x\": \"journal_name\"})\n",
    "\n",
    "print(f\"Valeurs uniques des attributs de temp:\\n\"\n",
    "      f\"{get_uniqueness_attributes(temp)}\")\n",
    "\n",
    "data = pd.merge(temp, price, on=['issn'], how='outer')\n",
    "data = get_df_duplicated_rows_dropped(data)\n",
    "\n",
    "print(f\"Valeurs uniques des attributs de data:\\n\"\n",
    "      f\"{get_uniqueness_attributes(data)}\")\n",
    "print(f\"Ratio de valeurs vides pour les attributs de data:\\n\"\n",
    "      f\"{get_ratio_missing_values(data)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'assure bien que les valeurs de l'attribut issn de la nouvelle date (data) sont uniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Y-a-t-il une corrÃ©lation entre les catÃ©gories de journaux (attribut category) et les coÃ»ts de publication (attribut price)? Justifier la rÃ©ponse."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "labelled_data = data[data['category'].notna()]\n",
    "data_to_predict = data[data['category'].isna()]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "labelled_data['category'] = labelled_data['category'].str.replace(r'[\\.\\|&] | [\\.\\|&] ', '.', regex=True)\n",
    "category_dummies = labelled_data['category'].str.get_dummies(sep='.')\n",
    "category_dummies = category_dummies.add_prefix('category_')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "labelled_data = pd.concat([labelled_data, category_dummies], axis=1) \\\n",
    "    # .drop(columns=['category'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "categories_correlation = {}\n",
    "\n",
    "for header in category_dummies.columns:\n",
    "    corr = labelled_data[header].corr(labelled_data['price'])\n",
    "    if abs(corr) > 0.1:\n",
    "        categories_correlation[header] = corr\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(categories_correlation.keys(), categories_correlation.values())\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.title(f'CatÃ©gories prÃ©sentant des corrÃ©lations fortes avec l\\'attribut prix et leurs valeurs')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Construire un modÃ¨le pour prÃ©dire les valeurs de catÃ©gorie de journaux manquantes de la faÃ§on la plus prÃ©cise \n",
    "possible (cela inclut la sÃ©lection dâ€™attributs informatifs, le choix et le paramÃ©trage dâ€™un modÃ¨le de classification, \n",
    "le calcul du score du modÃ¨le, lâ€™application du modÃ¨le pour prÃ©dire les catÃ©gories manquantes). Justifier les choix \n",
    "effectuÃ©s."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "labelled_data = labelled_data[labelled_data['price'].notna()]\n",
    "\n",
    "headers = ['citation_count_sum', 'paper_count_sum', 'avg_cites_per_paper', 'proj_ai', 'price']\n",
    "labelled_data = labelled_data.dropna(axis=0, subset=headers)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "journal_name_score_match_category = pd.Series()\n",
    "publisher_name_score_match_category = pd.Series()\n",
    "\n",
    "labelled_data['journal_name_sm_category'] = labelled_data.apply(partial(get_score_sequence_matching, c1='journal_name',\n",
    "                                                                        c2='category'), axis=1)\n",
    "labelled_data['pub_name_sm_category'] = labelled_data.apply(partial(get_score_sequence_matching, c1='pub_name',\n",
    "                                                                    c2='category'), axis=1)\n",
    "# %%\n",
    "\n",
    "labelled_data = labelled_data.drop(columns=['category'])\n",
    "print(f'size labelled_data before splitting: {labelled_data.shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "attributes_of_interest = ['citation_count_sum', 'paper_count_sum', 'avg_cites_per_paper', 'proj_ai', 'price',\n",
    "                          # 'date_stamp',\n",
    "                          'journal_name_sm_category', 'pub_name_sm_category']\n",
    "headers = category_dummies.columns.tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "clfs = {'RandomForestClassifier': RandomForestClassifier()}\n",
    "\n",
    "best_model = {'name': '', 'score': 0, 'model': None}\n",
    "for name, clf in clfs.items():\n",
    "    # for i in range(13, 16): TODO\n",
    "    for i in range(14, 15):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(labelled_data.drop(columns=headers),\n",
    "                                                            labelled_data[category_dummies.columns],\n",
    "                                                            test_size=0.33, random_state=42)\n",
    "        X_train = X_train[attributes_of_interest]\n",
    "        X_test = X_test[attributes_of_interest]\n",
    "        y_train = y_train.to_numpy()\n",
    "\n",
    "        clf.set_params(max_depth=i)\n",
    "\n",
    "        print(f'ModÃ¨le {name} {i}')\n",
    "        print('## Entrainement ##')\n",
    "        classifier = MultiOutputClassifier(clf, n_jobs=-1)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        train_score = classifier.score(X_train, y_train)\n",
    "        print(f'Score d\\'entraÃ®nement: {train_score}')\n",
    "\n",
    "        print('## Test ##')\n",
    "        test_predictions = classifier.predict(X_test)\n",
    "        test_score = classifier.score(X_test, y_test)\n",
    "        print(f'Score de test: {test_score}')\n",
    "\n",
    "        if test_score > best_model.get('score'):\n",
    "            best_model['name'], best_model['score'], best_model['model'] = name + ' ' + str(i), test_score, clf\n",
    "\n",
    "print(f\"Le modÃ¨le prÃ©sentant le meilleur score est {best_model.get('name')} avec {best_model.get('score')}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RÃ©sultats des diffÃ©rents essais:\n",
    "\n",
    "ModÃ¨le KNeighborsClassifier 3\n",
    "## Entrainement ##\n",
    "Score d'entraÃ®nement: 0.6727145847871598\n",
    "## Test ##\n",
    "Score de test: 0.3988684582743989\n",
    "\n",
    "ModÃ¨le RandomForestClassifier 14\n",
    "## Entrainement ##\n",
    "Score d'entraÃ®nement: 0.9993021632937893\n",
    "## Test ##\n",
    "Score de test: 0.7199434229137199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: RÃ©grÃ©ssion-clustering\n",
    "## A. Supprimer tous les attributs ayant plus de 50% de donnÃ©es manquantes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}